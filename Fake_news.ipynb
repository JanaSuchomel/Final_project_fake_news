{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C_EwZ9sfbPkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "126ade47-5e07-4807-cace-4c7caeeb39af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                              title  \\\n",
            "0           0  Sanders back in U.S. Senate, blasts 'coloniali...   \n",
            "1           1  Kremlin: Syria peoples' congress being 'active...   \n",
            "2           2   Oregon Cop Convicted Of Shattering Biker‚Äôs Co...   \n",
            "3           3   Twitter Erupts With Glee Over #CruzSexScandal...   \n",
            "4           4  MUST WATCH VIDEO: Obama Tries To Trash Trump B...   \n",
            "\n",
            "                                                text  label  \n",
            "0  WASHINGTON (Reuters) - Democratic U.S. preside...      1  \n",
            "1  MOSCOW (Reuters) - A proposal to convene a con...      1  \n",
            "2  In a baffling fit of rage, an Oregon State Pol...      0  \n",
            "3  The last thing any politician running for the ...      0  \n",
            "4  This is too good to miss! Mr. Teleprompter did...      0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('evaluation.csv', sep=';')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('test (1).csv', sep=';')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeT1eoTreHR2",
        "outputId": "82ce4a82-e162-4568-e9ea-54e45d25668f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                              title  \\\n",
            "0           0  Live from New York, it's a Trump-Clinton remat...   \n",
            "1           1  Catalan separatists to lose majority in tight ...   \n",
            "2           2  North Carolina governor concedes election to D...   \n",
            "3           3  Draft Senate Iran legislation sets tough new U...   \n",
            "4           4  California governor taps U.S. Representative B...   \n",
            "\n",
            "                                                text  label  \n",
            "0  NEW YORK (Reuters) - Veteran actor and frequen...      1  \n",
            "1  BARCELONA (Reuters) - Catalonia s independence...      1  \n",
            "2  WINSTON-SALEM, N.C. (Reuters) - North Carolina...      1  \n",
            "3  WASHINGTON (Reuters) - Draft legislation respo...      1  \n",
            "4  SACRAMENTO, Calif. (Reuters) - California Gove...      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "with open('evaluation.csv', \"r\", encoding=\"utf-8\") as f:\n",
        "    delimiter = csv.Sniffer().sniff(f.readline()).delimiter\n",
        "\n",
        "eval_df = pd.read_csv('evaluation.csv', delimiter=delimiter)\n",
        "\n",
        "print(f\"Detekovan√Ω oddƒõlovaƒç: '{delimiter}'\")\n",
        "print(eval_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UQlsRk0ezL6",
        "outputId": "b3c0eb9b-ee43-4c6e-b1bc-812fcde2104a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detekovan√Ω oddƒõlovaƒç: ';'\n",
            "   Unnamed: 0                                              title  \\\n",
            "0           0  Sanders back in U.S. Senate, blasts 'coloniali...   \n",
            "1           1  Kremlin: Syria peoples' congress being 'active...   \n",
            "2           2   Oregon Cop Convicted Of Shattering Biker‚Äôs Co...   \n",
            "3           3   Twitter Erupts With Glee Over #CruzSexScandal...   \n",
            "4           4  MUST WATCH VIDEO: Obama Tries To Trash Trump B...   \n",
            "\n",
            "                                                text  label  \n",
            "0  WASHINGTON (Reuters) - Democratic U.S. preside...      1  \n",
            "1  MOSCOW (Reuters) - A proposal to convene a con...      1  \n",
            "2  In a baffling fit of rage, an Oregon State Pol...      0  \n",
            "3  The last thing any politician running for the ...      0  \n",
            "4  This is too good to miss! Mr. Teleprompter did...      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "with open('test (1).csv', \"r\", encoding=\"utf-8\") as f:\n",
        "    delimiter = csv.Sniffer().sniff(f.readline()).delimiter\n",
        "\n",
        "test_df = pd.read_csv('test (1).csv', delimiter=delimiter)\n",
        "\n",
        "print(f\"Detekovan√Ω oddƒõlovaƒç: '{delimiter}'\")\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJCrR7G4e0PA",
        "outputId": "08523d42-4f76-444c-9ae4-19e7f3c518a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detekovan√Ω oddƒõlovaƒç: ';'\n",
            "   Unnamed: 0                                              title  \\\n",
            "0           0  Live from New York, it's a Trump-Clinton remat...   \n",
            "1           1  Catalan separatists to lose majority in tight ...   \n",
            "2           2  North Carolina governor concedes election to D...   \n",
            "3           3  Draft Senate Iran legislation sets tough new U...   \n",
            "4           4  California governor taps U.S. Representative B...   \n",
            "\n",
            "                                                text  label  \n",
            "0  NEW YORK (Reuters) - Veteran actor and frequen...      1  \n",
            "1  BARCELONA (Reuters) - Catalonia s independence...      1  \n",
            "2  WINSTON-SALEM, N.C. (Reuters) - North Carolina...      1  \n",
            "3  WASHINGTON (Reuters) - Draft legislation respo...      1  \n",
            "4  SACRAMENTO, Calif. (Reuters) - California Gove...      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "with open('train (2).csv', \"r\", encoding=\"utf-8\") as f:\n",
        "    delimiter = csv.Sniffer().sniff(f.readline()).delimiter\n",
        "\n",
        "train_df = pd.read_csv('train (2).csv', delimiter=delimiter)\n",
        "\n",
        "print(f\"Detekovan√Ω oddƒõlovaƒç: '{delimiter}'\")\n",
        "print(train_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V4sYYvEfGjO",
        "outputId": "cbf99ad9-f637-4bd8-9df2-52bb9da3493a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detekovan√Ω oddƒõlovaƒç: ';'\n",
            "   Unnamed: 0                                              title  \\\n",
            "0           0  Palestinians switch off Christmas lights in Be...   \n",
            "1           1  China says Trump call with Taiwan president wo...   \n",
            "2           2   FAIL! The Trump Organization‚Äôs Credit Score W...   \n",
            "3           3  Zimbabwe military chief's China trip was norma...   \n",
            "4           4  THE MOST UNCOURAGEOUS PRESIDENT EVER Receives ...   \n",
            "\n",
            "                                                text  label  \n",
            "0  RAMALLAH, West Bank (Reuters) - Palestinians s...      1  \n",
            "1  BEIJING (Reuters) - U.S. President-elect Donal...      1  \n",
            "2  While the controversy over Trump s personal ta...      0  \n",
            "3  BEIJING (Reuters) - A trip to Beijing last wee...      1  \n",
            "4  There has never been a more UNCOURAGEOUS perso...      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Text Preprocessing and Label Encoding\n",
        "# Here we only need 'title', 'text', and 'label' columns\n",
        "train_df['content'] = train_df['title'] + \" \" + train_df['text']  # Combine title and text\n",
        "eval_df['content'] = eval_df['title'] + \" \" + eval_df['text']\n",
        "test_df['content'] = test_df['title'] + \" \" + test_df['text']\n",
        "\n",
        "# Encode the labels (1 for fake news, 0 otherwise)\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['label'] = label_encoder.fit_transform(train_df['label'])\n",
        "eval_df['label'] = label_encoder.transform(eval_df['label'])\n",
        "\n",
        "# Step 3: Train-Test Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    train_df['content'], train_df['label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 4: Vectorization using TF-IDF and Model Pipeline\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')\n",
        "\n",
        "# Create a pipeline with TF-IDF and Logistic Regression\n",
        "model_pipeline = Pipeline([\n",
        "    ('tfidf', tfidf_vectorizer),\n",
        "    ('clf', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Step 5: Model Training\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Evaluation on Validation Set\n",
        "y_pred_val = model_pipeline.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred_val)\n",
        "report = classification_report(y_val, y_pred_val)\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_val)\n",
        "\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", report)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Step 7: Evaluation on Test Set\n",
        "if 'label' in test_df.columns:\n",
        "    y_test = label_encoder.transform(test_df['label'])\n",
        "    y_pred_test = model_pipeline.predict(test_df['content'])\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "    test_report = classification_report(y_test, y_pred_test)\n",
        "    test_conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "    print(\"Test Accuracy:\", test_accuracy)\n",
        "    print(\"\\nTest Classification Report:\\n\", test_report)\n",
        "    print(\"\\nTest Confusion Matrix:\\n\", test_conf_matrix)\n",
        "else:\n",
        "    # If no labels are provided in test data, output predictions\n",
        "    test_predictions = model_pipeline.predict(test_df['content'])\n",
        "    test_df['predicted_label'] = label_encoder.inverse_transform(test_predictions)\n",
        "    test_df.to_csv('/kaggle/working/test_predictions.csv', index=False)\n",
        "    print(\"Predictions for test set saved to test_predictions.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMDVcZqPfS1t",
        "outputId": "1866fcb3-208e-4e55-9f22-d80adb757111"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9667419421063437\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96      2215\n",
            "           1       0.97      0.97      0.97      2656\n",
            "\n",
            "    accuracy                           0.97      4871\n",
            "   macro avg       0.97      0.97      0.97      4871\n",
            "weighted avg       0.97      0.97      0.97      4871\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[2140   75]\n",
            " [  87 2569]]\n",
            "Test Accuracy: 0.9721572009363065\n",
            "\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      3753\n",
            "           1       0.97      0.98      0.97      4364\n",
            "\n",
            "    accuracy                           0.97      8117\n",
            "   macro avg       0.97      0.97      0.97      8117\n",
            "weighted avg       0.97      0.97      0.97      8117\n",
            "\n",
            "\n",
            "Test Confusion Matrix:\n",
            " [[3634  119]\n",
            " [ 107 4257]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# üìå 1Ô∏è‚É£ **Naƒçten√≠ dataset≈Ø**\n",
        "test_df  = pd.read_csv('test (1).csv', sep=';')\n",
        "train_df  = pd.read_csv('train (2).csv', sep=';')\n",
        "\n",
        "# üìå 2Ô∏è‚É£ **P≈ôedzpracov√°n√≠ dat**\n",
        "# P≈ôedpokl√°d√°m, ≈æe posledn√≠ sloupec je c√≠lov√° promƒõnn√° (y)\n",
        "target_column = train_df.columns[-1]  # Oznaƒçen√≠ c√≠lov√©ho sloupce\n",
        "X_train = train_df.drop(columns=[target_column])\n",
        "y_train = train_df[target_column]\n",
        "\n",
        "X_test = test_df.drop(columns=[target_column])\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "# üìå **Pou≈æit√≠ stejn√©ho LabelEncoder pro tr√©novac√≠ i testovac√≠ data**\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Nejd≈ô√≠ve nauƒç√≠me encoder na y_train\n",
        "encoder.fit(y_train)\n",
        "\n",
        "# Pak p≈ôevedeme obƒõ sady dat\n",
        "y_train = encoder.transform(y_train)\n",
        "y_test = encoder.transform(y_test)  # Pou≈æ√≠v√°me stejn√Ω encoder, aby nebyla chyba\n",
        "\n",
        "# P≈ôevod na one-hot encoding (pro neuronovou s√≠≈•)\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "# Zpracov√°n√≠ textov√Ωch sloupc≈Ø\n",
        "text_columns = X_train.select_dtypes(include=['object']).columns\n",
        "for col in text_columns:\n",
        "    le = LabelEncoder()\n",
        "    X_train[col] = le.fit_transform(X_train[col])\n",
        "    X_test[col] = le.transform(X_test[col])\n",
        "\n",
        "# Normalizace ƒç√≠seln√Ωch dat\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# üìå 3Ô∏è‚É£ **Vytvo≈ôen√≠ neuronov√© s√≠tƒõ**\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  # Vstupn√≠ vrstva\n",
        "    Dropout(0.3),  # Dropout pro sn√≠≈æen√≠ p≈ôeuƒçen√≠\n",
        "    Dense(64, activation='relu'),  # Skryt√° vrstva\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),  # Dal≈°√≠ skryt√° vrstva\n",
        "    Dense(y_train.shape[1], activation='softmax')  # V√Ωstupn√≠ vrstva (softmax pro v√≠ce t≈ô√≠d)\n",
        "])\n",
        "\n",
        "# üìå 4Ô∏è‚É£ **Kompilace modelu**\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# üìå 5Ô∏è‚É£ **Tr√©nov√°n√≠ modelu**\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# üìå 6Ô∏è‚É£ **Vyhodnocen√≠ modelu**\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # P≈ôeveden√≠ pravdƒõpodobnost√≠ na t≈ô√≠dy\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Zobrazen√≠ klasifikaƒçn√≠ho reportu\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_classes, y_pred_classes))\n",
        "\n",
        "# Zobrazen√≠ matice z√°mƒõn\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_classes, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "VyvEWWMWnqFk",
        "outputId": "43c1f3b0-69e2-4c36-c3b5-7296608d5fdf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "y contains previously unseen labels: \"Live from New York, it's a Trump-Clinton rematch - of sorts\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Live from New York, it's a Trump-Clinton rematch - of sorts\"",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5d22a4e9a5a9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Normalizace ƒç√≠seln√Ωch dat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"y contains previously unseen labels: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_unknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: \"Live from New York, it's a Trump-Clinton rematch - of sorts\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# data sets\n",
        "test_df = pd.read_csv('test (1).csv', sep=';')\n",
        "train_df = pd.read_csv('train (2).csv', sep=';')\n",
        "\n",
        "# processing data\n",
        "target_column = train_df.columns[-1]  #target column\n",
        "X_train = train_df.drop(columns=[target_column])\n",
        "y_train = train_df[target_column]\n",
        "\n",
        "X_test = test_df.drop(columns=[target_column])\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "# use same LabelEncoder for testing and training data\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# learning encoder on y_train\n",
        "encoder.fit(y_train)\n",
        "\n",
        "# transform both data sets\n",
        "y_train = encoder.transform(y_train)\n",
        "y_test = encoder.transform(y_test)  # Pou≈æ√≠v√°me stejn√Ω encoder, aby nebyla chyba\n",
        "\n",
        "# transfer to  one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "# processing text columns\n",
        "text_columns = X_train.select_dtypes(include=['object']).columns\n",
        "for col in text_columns:\n",
        "    le = LabelEncoder()\n",
        "    # Fit the LabelEncoder on the combined unique values from both train and test\n",
        "    all_values = pd.concat([X_train[col], X_test[col]]).unique()\n",
        "    le.fit(all_values)\n",
        "    X_train[col] = le.transform(X_train[col])\n",
        "    X_test[col] = le.transform(X_test[col])\n",
        "\n",
        "# normalize numbers columns\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# neural network creation\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer\"\n",
        "    Dropout(0.3),  # Dropout to reduce overfitting\n",
        "    Dense(64, activation='relu'),  # Hidden layer\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),  # Hidden layer\n",
        "    Dense(y_train.shape[1], activation='softmax')  # Output layer (softmax for multiple classes)\n",
        "])\n",
        "\n",
        "# Model compilation\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# training model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# model evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  #converting probabilities to classes\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# displaying the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_classes, y_pred_classes))\n",
        "\n",
        "# displaying the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_classes, y_pred_classes))"
      ],
      "metadata": {
        "id": "B8eeO0nmofFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt\n"
      ],
      "metadata": {
        "id": "o8ts8Qc4AXCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_curve, auc\n",
        "\n",
        "# ‚úÖ Cesta k dat≈Øm (Uprav dle pot≈ôeby)\n",
        "data_path = \"C:\\\\Users\\\\fake_news\\\\\"\n",
        "\n",
        "# ‚úÖ Naƒçten√≠ dataset≈Ø\n",
        "train_df = pd.read_csv(data_path + \"train.csv\", sep=';')\n",
        "test_df = pd.read_csv(data_path + \"test.csv\", sep=';')\n",
        "submit_df = pd.read_csv(data_path + \"submit.csv\", sep=';')\n",
        "\n",
        "# ‚úÖ Spojen√≠ testovac√≠ch dat\n",
        "test_df = pd.concat([test_df, submit_df], axis=1).drop(\"idS\", axis=1)\n",
        "df_all = pd.concat([train_df, test_df])\n",
        "\n",
        "\n",
        "# ‚úÖ Rozdƒõlen√≠ na vstupn√≠ (X) a v√Ωstupn√≠ (Y) data\n",
        "target_column = df_all.columns[-1]\n",
        "X = df_all.drop(columns=[target_column])\n",
        "Y = df_all[target_column]\n",
        "\n",
        "# ‚úÖ Label Encoding pro v√Ωstupn√≠ data\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(Y)\n",
        "Y = keras.utils.to_categorical(Y)  # P≈ôevod na one-hot encoding\n",
        "\n",
        "# ‚úÖ Zpracov√°n√≠ textov√Ωch sloupc≈Ø\n",
        "text_columns = X.select_dtypes(include=['object']).columns\n",
        "for col in text_columns:\n",
        "    le = LabelEncoder()\n",
        "    all_values = pd.concat([X[col], X[col]]).unique()  # Slouƒçen√≠ hodnot z tr√©novac√≠ch a testovac√≠ch dat\n",
        "    le.fit(all_values)\n",
        "    X[col] = le.transform(X[col])\n",
        "\n",
        "# ‚úÖ Normalizace ƒç√≠seln√Ωch sloupc≈Ø\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# ‚úÖ Tokenizace textov√Ωch dat (pokud je sloupec `title`)\n",
        "if 'title' in df_all.columns:\n",
        "    max_features = 5000\n",
        "    max_len = 40\n",
        "    tokenizer = Tokenizer(num_words=max_features)\n",
        "    X_title = df_all['title'].astype(str).fillna(\"\")\n",
        "    tokenizer.fit_on_texts(X_title)\n",
        "    sequences = tokenizer.texts_to_sequences(X_title)\n",
        "    X_title = pad_sequences(sequences, maxlen=max_len, padding=\"pre\")\n",
        "else:\n",
        "    X_title = None\n",
        "\n",
        "# ‚úÖ Rozdƒõlen√≠ na tr√©novac√≠ a testovac√≠ sady\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ‚úÖ Vytvo≈ôen√≠ neuronov√© s√≠tƒõ\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  # Vstupn√≠ vrstva\n",
        "    Dropout(0.3),  # Dropout pro sn√≠≈æen√≠ p≈ôeuƒçen√≠\n",
        "    Dense(64, activation='relu'),  # Skryt√° vrstva\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),  # Skryt√° vrstva\n",
        "    Dense(y_train.shape[1], activation='softmax')  # V√Ωstupn√≠ vrstva (softmax pro v√≠ce t≈ô√≠d)\n",
        "])\n",
        "\n",
        "# ‚úÖ Kompilace modelu\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# ‚úÖ Tr√©nov√°n√≠ modelu\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# ‚úÖ Zobrazen√≠ pr≈Øbƒõhu tr√©nov√°n√≠\n",
        "history_dict = history.history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_dict[\"loss\"], \"ro\", label=\"Training loss\")\n",
        "plt.plot(history_dict[\"val_loss\"], \"r\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_dict[\"accuracy\"], \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(history_dict[\"val_accuracy\"], \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# ‚úÖ Predikce na testovac√≠ch datech\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # P≈ôevod pravdƒõpodobnost√≠ na t≈ô√≠dy\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# ‚úÖ Zobrazen√≠ klasifikaƒçn√≠ho reportu\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_classes, y_pred_classes))\n",
        "\n",
        "# ‚úÖ Zobrazen√≠ matice z√°mƒõn\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_classes, y_pred_classes))\n",
        "\n",
        "# ‚úÖ ROC k≈ôivka a AUC sk√≥re\n",
        "y_pred_proba = y_pred.ravel()\n",
        "fpr, tpr, thresholds = roc_curve(y_test_classes, y_pred_proba)\n",
        "auc_score = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC (AUC = {auc_score:.3f})')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# ‚úÖ Vyhodnocen√≠ modelu\n",
        "results = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nModel Loss: {results[0]}, Accuracy: {results[1]}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dTH2urJ_BzRo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}