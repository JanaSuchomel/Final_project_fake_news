{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanaSuchomel/Final_project_fake_news/blob/main/Fake_news_kod.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_EwZ9sfbPkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c6b843-c34f-4bdc-93c7-6a7d81f511a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                              title  \\\n",
            "0           0  Sanders back in U.S. Senate, blasts 'coloniali...   \n",
            "1           1  Kremlin: Syria peoples' congress being 'active...   \n",
            "2           2   Oregon Cop Convicted Of Shattering Bikerâ€™s Co...   \n",
            "3           3   Twitter Erupts With Glee Over #CruzSexScandal...   \n",
            "4           4  MUST WATCH VIDEO: Obama Tries To Trash Trump B...   \n",
            "\n",
            "                                                text  label  \n",
            "0  WASHINGTON (Reuters) - Democratic U.S. preside...      1  \n",
            "1  MOSCOW (Reuters) - A proposal to convene a con...      1  \n",
            "2  In a baffling fit of rage, an Oregon State Pol...      0  \n",
            "3  The last thing any politician running for the ...      0  \n",
            "4  This is too good to miss! Mr. Teleprompter did...      0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('evaluation.csv', sep=';')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('test (1).csv', sep=';')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeT1eoTreHR2",
        "outputId": "0f83263e-368c-43de-d38a-6218462549e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                              title  \\\n",
            "0           0  Live from New York, it's a Trump-Clinton remat...   \n",
            "1           1  Catalan separatists to lose majority in tight ...   \n",
            "2           2  North Carolina governor concedes election to D...   \n",
            "3           3  Draft Senate Iran legislation sets tough new U...   \n",
            "4           4  California governor taps U.S. Representative B...   \n",
            "\n",
            "                                                text  label  \n",
            "0  NEW YORK (Reuters) - Veteran actor and frequen...      1  \n",
            "1  BARCELONA (Reuters) - Catalonia s independence...      1  \n",
            "2  WINSTON-SALEM, N.C. (Reuters) - North Carolina...      1  \n",
            "3  WASHINGTON (Reuters) - Draft legislation respo...      1  \n",
            "4  SACRAMENTO, Calif. (Reuters) - California Gove...      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "with open('evaluation.csv', \"r\", encoding=\"utf-8\") as f:\n",
        "    delimiter = csv.Sniffer().sniff(f.readline()).delimiter\n",
        "\n",
        "eval_df = pd.read_csv('evaluation.csv', delimiter=delimiter)\n",
        "\n",
        "print(f\"DetekovanÃ½ oddÄ›lovaÄ: '{delimiter}'\")\n",
        "print(eval_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UQlsRk0ezL6",
        "outputId": "ed731da6-0de5-410b-df6d-6962a35a4d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DetekovanÃ½ oddÄ›lovaÄ: ';'\n",
            "   Unnamed: 0                                              title  \\\n",
            "0           0  Sanders back in U.S. Senate, blasts 'coloniali...   \n",
            "1           1  Kremlin: Syria peoples' congress being 'active...   \n",
            "2           2   Oregon Cop Convicted Of Shattering Bikerâ€™s Co...   \n",
            "3           3   Twitter Erupts With Glee Over #CruzSexScandal...   \n",
            "4           4  MUST WATCH VIDEO: Obama Tries To Trash Trump B...   \n",
            "\n",
            "                                                text  label  \n",
            "0  WASHINGTON (Reuters) - Democratic U.S. preside...      1  \n",
            "1  MOSCOW (Reuters) - A proposal to convene a con...      1  \n",
            "2  In a baffling fit of rage, an Oregon State Pol...      0  \n",
            "3  The last thing any politician running for the ...      0  \n",
            "4  This is too good to miss! Mr. Teleprompter did...      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "with open('test (1).csv', \"r\", encoding=\"utf-8\") as f:\n",
        "    delimiter = csv.Sniffer().sniff(f.readline()).delimiter\n",
        "\n",
        "test_df = pd.read_csv('test (1).csv', delimiter=delimiter)\n",
        "\n",
        "print(f\"DetekovanÃ½ oddÄ›lovaÄ: '{delimiter}'\")\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJCrR7G4e0PA",
        "outputId": "7156ac1c-6912-4320-b7b7-62384e8675b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DetekovanÃ½ oddÄ›lovaÄ: ';'\n",
            "   Unnamed: 0                                              title  \\\n",
            "0           0  Live from New York, it's a Trump-Clinton remat...   \n",
            "1           1  Catalan separatists to lose majority in tight ...   \n",
            "2           2  North Carolina governor concedes election to D...   \n",
            "3           3  Draft Senate Iran legislation sets tough new U...   \n",
            "4           4  California governor taps U.S. Representative B...   \n",
            "\n",
            "                                                text  label  \n",
            "0  NEW YORK (Reuters) - Veteran actor and frequen...      1  \n",
            "1  BARCELONA (Reuters) - Catalonia s independence...      1  \n",
            "2  WINSTON-SALEM, N.C. (Reuters) - North Carolina...      1  \n",
            "3  WASHINGTON (Reuters) - Draft legislation respo...      1  \n",
            "4  SACRAMENTO, Calif. (Reuters) - California Gove...      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "with open('train (2).csv', \"r\", encoding=\"utf-8\") as f:\n",
        "    delimiter = csv.Sniffer().sniff(f.readline()).delimiter\n",
        "\n",
        "train_df = pd.read_csv('train (2).csv', delimiter=delimiter)\n",
        "\n",
        "print(f\"DetekovanÃ½ oddÄ›lovaÄ: '{delimiter}'\")\n",
        "print(train_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V4sYYvEfGjO",
        "outputId": "7a2e8e4a-a52e-4aa9-8e18-4803b007a186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DetekovanÃ½ oddÄ›lovaÄ: ';'\n",
            "   Unnamed: 0                                              title  \\\n",
            "0           0  Palestinians switch off Christmas lights in Be...   \n",
            "1           1  China says Trump call with Taiwan president wo...   \n",
            "2           2   FAIL! The Trump Organizationâ€™s Credit Score W...   \n",
            "3           3  Zimbabwe military chief's China trip was norma...   \n",
            "4           4  THE MOST UNCOURAGEOUS PRESIDENT EVER Receives ...   \n",
            "\n",
            "                                                text  label  \n",
            "0  RAMALLAH, West Bank (Reuters) - Palestinians s...      1  \n",
            "1  BEIJING (Reuters) - U.S. President-elect Donal...      1  \n",
            "2  While the controversy over Trump s personal ta...      0  \n",
            "3  BEIJING (Reuters) - A trip to Beijing last wee...      1  \n",
            "4  There has never been a more UNCOURAGEOUS perso...      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Text Preprocessing and Label Encoding\n",
        "# Here we only need 'title', 'text', and 'label' columns\n",
        "train_df['content'] = train_df['title'] + \" \" + train_df['text']  # Combine title and text\n",
        "eval_df['content'] = eval_df['title'] + \" \" + eval_df['text']\n",
        "test_df['content'] = test_df['title'] + \" \" + test_df['text']\n",
        "\n",
        "# Encode the labels (1 for fake news, 0 otherwise)\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['label'] = label_encoder.fit_transform(train_df['label'])\n",
        "eval_df['label'] = label_encoder.transform(eval_df['label'])\n",
        "\n",
        "# Step 3: Train-Test Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    train_df['content'], train_df['label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 4: Vectorization using TF-IDF and Model Pipeline\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')\n",
        "\n",
        "# Create a pipeline with TF-IDF and Logistic Regression\n",
        "model_pipeline = Pipeline([\n",
        "    ('tfidf', tfidf_vectorizer),\n",
        "    ('clf', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Step 5: Model Training\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Evaluation on Validation Set\n",
        "y_pred_val = model_pipeline.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred_val)\n",
        "report = classification_report(y_val, y_pred_val)\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_val)\n",
        "\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", report)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Step 7: Evaluation on Test Set\n",
        "if 'label' in test_df.columns:\n",
        "    y_test = label_encoder.transform(test_df['label'])\n",
        "    y_pred_test = model_pipeline.predict(test_df['content'])\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "    test_report = classification_report(y_test, y_pred_test)\n",
        "    test_conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "    print(\"Test Accuracy:\", test_accuracy)\n",
        "    print(\"\\nTest Classification Report:\\n\", test_report)\n",
        "    print(\"\\nTest Confusion Matrix:\\n\", test_conf_matrix)\n",
        "else:\n",
        "    # If no labels are provided in test data, output predictions\n",
        "    test_predictions = model_pipeline.predict(test_df['content'])\n",
        "    test_df['predicted_label'] = label_encoder.inverse_transform(test_predictions)\n",
        "    test_df.to_csv('/kaggle/working/test_predictions.csv', index=False)\n",
        "    print(\"Predictions for test set saved to test_predictions.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMDVcZqPfS1t",
        "outputId": "464210b1-5335-4190-8c39-c54e2a37cc0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9667419421063437\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96      2215\n",
            "           1       0.97      0.97      0.97      2656\n",
            "\n",
            "    accuracy                           0.97      4871\n",
            "   macro avg       0.97      0.97      0.97      4871\n",
            "weighted avg       0.97      0.97      0.97      4871\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[2140   75]\n",
            " [  87 2569]]\n",
            "Test Accuracy: 0.9721572009363065\n",
            "\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      3753\n",
            "           1       0.97      0.98      0.97      4364\n",
            "\n",
            "    accuracy                           0.97      8117\n",
            "   macro avg       0.97      0.97      0.97      8117\n",
            "weighted avg       0.97      0.97      0.97      8117\n",
            "\n",
            "\n",
            "Test Confusion Matrix:\n",
            " [[3634  119]\n",
            " [ 107 4257]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ğŸ“Œ 1ï¸âƒ£ **NaÄtenÃ­ datasetÅ¯**\n",
        "test_df  = pd.read_csv('test (1).csv', sep=';')\n",
        "train_df  = pd.read_csv('train (2).csv', sep=';')\n",
        "\n",
        "# ğŸ“Œ 2ï¸âƒ£ **PÅ™edzpracovÃ¡nÃ­ dat**\n",
        "# PÅ™edpoklÃ¡dÃ¡m, Å¾e poslednÃ­ sloupec je cÃ­lovÃ¡ promÄ›nnÃ¡ (y)\n",
        "target_column = train_df.columns[-1]  # OznaÄenÃ­ cÃ­lovÃ©ho sloupce\n",
        "X_train = train_df.drop(columns=[target_column])\n",
        "y_train = train_df[target_column]\n",
        "\n",
        "X_test = test_df.drop(columns=[target_column])\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "# ğŸ“Œ **PouÅ¾itÃ­ stejnÃ©ho LabelEncoder pro trÃ©novacÃ­ i testovacÃ­ data**\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# NejdÅ™Ã­ve nauÄÃ­me encoder na y_train\n",
        "encoder.fit(y_train)\n",
        "\n",
        "# Pak pÅ™evedeme obÄ› sady dat\n",
        "y_train = encoder.transform(y_train)\n",
        "y_test = encoder.transform(y_test)  # PouÅ¾Ã­vÃ¡me stejnÃ½ encoder, aby nebyla chyba\n",
        "\n",
        "# PÅ™evod na one-hot encoding (pro neuronovou sÃ­Å¥)\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "# ZpracovÃ¡nÃ­ textovÃ½ch sloupcÅ¯\n",
        "text_columns = X_train.select_dtypes(include=['object']).columns\n",
        "for col in text_columns:\n",
        "    le = LabelEncoder()\n",
        "    X_train[col] = le.fit_transform(X_train[col])\n",
        "    X_test[col] = le.transform(X_test[col])\n",
        "\n",
        "# Normalizace ÄÃ­selnÃ½ch dat\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# ğŸ“Œ 3ï¸âƒ£ **VytvoÅ™enÃ­ neuronovÃ© sÃ­tÄ›**\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  # VstupnÃ­ vrstva\n",
        "    Dropout(0.3),  # Dropout pro snÃ­Å¾enÃ­ pÅ™euÄenÃ­\n",
        "    Dense(64, activation='relu'),  # SkrytÃ¡ vrstva\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),  # DalÅ¡Ã­ skrytÃ¡ vrstva\n",
        "    Dense(y_train.shape[1], activation='softmax')  # VÃ½stupnÃ­ vrstva (softmax pro vÃ­ce tÅ™Ã­d)\n",
        "])\n",
        "\n",
        "# ğŸ“Œ 4ï¸âƒ£ **Kompilace modelu**\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ğŸ“Œ 5ï¸âƒ£ **TrÃ©novÃ¡nÃ­ modelu**\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# ğŸ“Œ 6ï¸âƒ£ **VyhodnocenÃ­ modelu**\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # PÅ™evedenÃ­ pravdÄ›podobnostÃ­ na tÅ™Ã­dy\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# ZobrazenÃ­ klasifikaÄnÃ­ho reportu\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_classes, y_pred_classes))\n",
        "\n",
        "# ZobrazenÃ­ matice zÃ¡mÄ›n\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_classes, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "VyvEWWMWnqFk",
        "outputId": "8aa9d9e5-f0f2-4046-9d88-42bde364db4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "y contains previously unseen labels: \"Live from New York, it's a Trump-Clinton rematch - of sorts\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Live from New York, it's a Trump-Clinton rematch - of sorts\"",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5d22a4e9a5a9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Normalizace ÄÃ­selnÃ½ch dat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"y contains previously unseen labels: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_unknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: \"Live from New York, it's a Trump-Clinton rematch - of sorts\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ğŸ“Œ 1ï¸âƒ£ **NaÄtenÃ­ datasetÅ¯**\n",
        "test_df = pd.read_csv('test (1).csv', sep=';')\n",
        "train_df = pd.read_csv('train (2).csv', sep=';')\n",
        "\n",
        "# ğŸ“Œ 2ï¸âƒ£ **PÅ™edzpracovÃ¡nÃ­ dat**\n",
        "# PÅ™edpoklÃ¡dÃ¡m, Å¾e poslednÃ­ sloupec je cÃ­lovÃ¡ promÄ›nnÃ¡ (y)\n",
        "target_column = train_df.columns[-1]  # OznaÄenÃ­ cÃ­lovÃ©ho sloupce\n",
        "X_train = train_df.drop(columns=[target_column])\n",
        "y_train = train_df[target_column]\n",
        "\n",
        "X_test = test_df.drop(columns=[target_column])\n",
        "y_test = test_df[target_column]\n",
        "\n",
        "# ğŸ“Œ **PouÅ¾itÃ­ stejnÃ©ho LabelEncoder pro trÃ©novacÃ­ i testovacÃ­ data**\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# NejdÅ™Ã­ve nauÄÃ­me encoder na y_train\n",
        "encoder.fit(y_train)\n",
        "\n",
        "# Pak pÅ™evedeme obÄ› sady dat\n",
        "y_train = encoder.transform(y_train)\n",
        "y_test = encoder.transform(y_test)  # PouÅ¾Ã­vÃ¡me stejnÃ½ encoder, aby nebyla chyba\n",
        "\n",
        "# PÅ™evod na one-hot encoding (pro neuronovou sÃ­Å¥)\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "# ZpracovÃ¡nÃ­ textovÃ½ch sloupcÅ¯\n",
        "text_columns = X_train.select_dtypes(include=['object']).columns\n",
        "for col in text_columns:\n",
        "    le = LabelEncoder()\n",
        "    # Fit the LabelEncoder on the combined unique values from both train and test\n",
        "    all_values = pd.concat([X_train[col], X_test[col]]).unique()\n",
        "    le.fit(all_values)\n",
        "    X_train[col] = le.transform(X_train[col])\n",
        "    X_test[col] = le.transform(X_test[col])\n",
        "\n",
        "# Normalizace ÄÃ­selnÃ½ch dat\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# ğŸ“Œ 3ï¸âƒ£ **VytvoÅ™enÃ­ neuronovÃ© sÃ­tÄ›**\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  # VstupnÃ­ vrstva\n",
        "    Dropout(0.3),  # Dropout pro snÃ­Å¾enÃ­ pÅ™euÄenÃ­\n",
        "    Dense(64, activation='relu'),  # SkrytÃ¡ vrstva\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),  # DalÅ¡Ã­ skrytÃ¡ vrstva\n",
        "    Dense(y_train.shape[1], activation='softmax')  # VÃ½stupnÃ­ vrstva (softmax pro vÃ­ce tÅ™Ã­d)\n",
        "])\n",
        "\n",
        "# ğŸ“Œ 4ï¸âƒ£ **Kompilace modelu**\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ğŸ“Œ 5ï¸âƒ£ **TrÃ©novÃ¡nÃ­ modelu**\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# ğŸ“Œ 6ï¸âƒ£ **VyhodnocenÃ­ modelu**\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # PÅ™evedenÃ­ pravdÄ›podobnostÃ­ na tÅ™Ã­dy\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# ZobrazenÃ­ klasifikaÄnÃ­ho reportu\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_classes, y_pred_classes))\n",
        "\n",
        "# ZobrazenÃ­ matice zÃ¡mÄ›n\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_classes, y_pred_classes))"
      ],
      "metadata": {
        "id": "B8eeO0nmofFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c417b68-838a-4e5c-e99f-074c02b6e0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7198 - loss: 0.5588 - val_accuracy: 0.7541 - val_loss: 0.4927\n",
            "Epoch 2/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7591 - loss: 0.4935 - val_accuracy: 0.7648 - val_loss: 0.4735\n",
            "Epoch 3/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7615 - loss: 0.4840 - val_accuracy: 0.7684 - val_loss: 0.4604\n",
            "Epoch 4/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7643 - loss: 0.4717 - val_accuracy: 0.7738 - val_loss: 0.4565\n",
            "Epoch 5/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7648 - loss: 0.4649 - val_accuracy: 0.7700 - val_loss: 0.4415\n",
            "Epoch 6/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7698 - loss: 0.4499 - val_accuracy: 0.7744 - val_loss: 0.4260\n",
            "Epoch 7/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7802 - loss: 0.4334 - val_accuracy: 0.7784 - val_loss: 0.4147\n",
            "Epoch 8/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.4236 - val_accuracy: 0.7941 - val_loss: 0.3935\n",
            "Epoch 9/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7893 - loss: 0.4054 - val_accuracy: 0.8184 - val_loss: 0.3764\n",
            "Epoch 10/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8003 - loss: 0.3900 - val_accuracy: 0.7989 - val_loss: 0.3754\n",
            "Epoch 11/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8034 - loss: 0.3929 - val_accuracy: 0.8203 - val_loss: 0.3638\n",
            "Epoch 12/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8068 - loss: 0.3821 - val_accuracy: 0.8296 - val_loss: 0.3527\n",
            "Epoch 13/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.3801 - val_accuracy: 0.8267 - val_loss: 0.3571\n",
            "Epoch 14/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.3804 - val_accuracy: 0.8302 - val_loss: 0.3473\n",
            "Epoch 15/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.3730 - val_accuracy: 0.8267 - val_loss: 0.3456\n",
            "Epoch 16/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8154 - loss: 0.3745 - val_accuracy: 0.8310 - val_loss: 0.3402\n",
            "Epoch 17/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8247 - loss: 0.3619 - val_accuracy: 0.8363 - val_loss: 0.3463\n",
            "Epoch 18/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8180 - loss: 0.3702 - val_accuracy: 0.8407 - val_loss: 0.3350\n",
            "Epoch 19/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8224 - loss: 0.3647 - val_accuracy: 0.8359 - val_loss: 0.3402\n",
            "Epoch 20/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.3631 - val_accuracy: 0.8334 - val_loss: 0.3396\n",
            "Epoch 21/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8230 - loss: 0.3607 - val_accuracy: 0.8364 - val_loss: 0.3423\n",
            "Epoch 22/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8212 - loss: 0.3618 - val_accuracy: 0.8368 - val_loss: 0.3305\n",
            "Epoch 23/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8210 - loss: 0.3647 - val_accuracy: 0.8408 - val_loss: 0.3287\n",
            "Epoch 24/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8274 - loss: 0.3547 - val_accuracy: 0.8374 - val_loss: 0.3336\n",
            "Epoch 25/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8269 - loss: 0.3587 - val_accuracy: 0.8321 - val_loss: 0.3472\n",
            "Epoch 26/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.3538 - val_accuracy: 0.8445 - val_loss: 0.3323\n",
            "Epoch 27/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 0.3577 - val_accuracy: 0.8438 - val_loss: 0.3334\n",
            "Epoch 28/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8285 - loss: 0.3548 - val_accuracy: 0.8228 - val_loss: 0.3584\n",
            "Epoch 29/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.3560 - val_accuracy: 0.8454 - val_loss: 0.3245\n",
            "Epoch 30/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8272 - loss: 0.3536 - val_accuracy: 0.8414 - val_loss: 0.3395\n",
            "Epoch 31/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8231 - loss: 0.3563 - val_accuracy: 0.8414 - val_loss: 0.3293\n",
            "Epoch 32/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8282 - loss: 0.3508 - val_accuracy: 0.8406 - val_loss: 0.3314\n",
            "Epoch 33/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8280 - loss: 0.3522 - val_accuracy: 0.8475 - val_loss: 0.3254\n",
            "Epoch 34/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8316 - loss: 0.3508 - val_accuracy: 0.8449 - val_loss: 0.3264\n",
            "Epoch 35/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8307 - loss: 0.3502 - val_accuracy: 0.8380 - val_loss: 0.3304\n",
            "Epoch 36/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8290 - loss: 0.3521 - val_accuracy: 0.8352 - val_loss: 0.3336\n",
            "Epoch 37/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8316 - loss: 0.3484 - val_accuracy: 0.8458 - val_loss: 0.3195\n",
            "Epoch 38/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8336 - loss: 0.3473 - val_accuracy: 0.8440 - val_loss: 0.3284\n",
            "Epoch 39/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8266 - loss: 0.3477 - val_accuracy: 0.8384 - val_loss: 0.3370\n",
            "Epoch 40/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8284 - loss: 0.3489 - val_accuracy: 0.8397 - val_loss: 0.3314\n",
            "Epoch 41/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.3499 - val_accuracy: 0.8391 - val_loss: 0.3258\n",
            "Epoch 42/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8275 - loss: 0.3501 - val_accuracy: 0.8380 - val_loss: 0.3359\n",
            "Epoch 43/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8328 - loss: 0.3487 - val_accuracy: 0.8444 - val_loss: 0.3269\n",
            "Epoch 44/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8330 - loss: 0.3491 - val_accuracy: 0.8448 - val_loss: 0.3273\n",
            "Epoch 45/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8317 - loss: 0.3481 - val_accuracy: 0.8481 - val_loss: 0.3240\n",
            "Epoch 46/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8336 - loss: 0.3448 - val_accuracy: 0.8487 - val_loss: 0.3300\n",
            "Epoch 47/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8293 - loss: 0.3483 - val_accuracy: 0.8493 - val_loss: 0.3144\n",
            "Epoch 48/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8324 - loss: 0.3431 - val_accuracy: 0.8497 - val_loss: 0.3239\n",
            "Epoch 49/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8307 - loss: 0.3482 - val_accuracy: 0.8454 - val_loss: 0.3199\n",
            "Epoch 50/50\n",
            "\u001b[1m762/762\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8361 - loss: 0.3406 - val_accuracy: 0.8529 - val_loss: 0.3192\n",
            "\u001b[1m254/254\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84      3753\n",
            "           1       0.85      0.88      0.87      4364\n",
            "\n",
            "    accuracy                           0.85      8117\n",
            "   macro avg       0.85      0.85      0.85      8117\n",
            "weighted avg       0.85      0.85      0.85      8117\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3067  686]\n",
            " [ 508 3856]]\n"
          ]
        }
      ]
    }
  ]
}